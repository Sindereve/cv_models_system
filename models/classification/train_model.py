import logging
import sys
from contextlib import contextmanager
import mlflow
from mlflow.types.schema import Schema, TensorSpec
from mlflow.models.signature import ModelSignature
from tqdm import tqdm
import numpy as np
import torch
from torch import nn
from torch import optim
from torch.optim import Optimizer, lr_scheduler
from torch.utils.data import DataLoader
from torchmetrics import MetricCollection
from torchmetrics.classification import (
    Accuracy, Recall, Precision, F1Score
)
from torchmetrics import MeanMetric

import time
from typing import Optional, Dict


class Trainer:
    def __init__(
            self, 
            model: nn.Module,
            # data
            train_loader: DataLoader,
            val_loader: DataLoader,
            test_loader: DataLoader = None,
            classes: Optional[Dict] = None,
            # settings for train model
            logger_lvl: str = 'debug',
            loss_fn: Optional[nn.Module] = None,
            optimizer: Optional[Optimizer] = None,
            scheduler: Optional[lr_scheduler._LRScheduler] = None,
            device: Optional[torch.device] = None,
            # mlflow tracking
            log_mlflow: bool = True,
            mlflow_uri: str = 'http://127.0.0.1:5000',
            log_artifacts: bool = True,
            experiment_name: str = "Experiment_name",
            run_name : Optional[str] = None,
            mlflow_tags: Optional[Dict[str, str]] = None,
        ):
        """
        Ğ¢Ñ€ĞµĞ½ĞµÑ€ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹.
        
        Args:
            model: ĞĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
            
            train_loader: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
            val_loader: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
            test_loader: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
            classes: ĞšĞ»Ğ°ÑÑÑ‹ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…(ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ[Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ: Ğ¸Ğ½Ğ´ĞµĞºÑ ĞºĞ»Ğ°ÑÑĞ°])

            logger_lvl: Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ· 3 Ğ²Ğ°Ñ€Ğ¸Ğ½Ñ‚Ğ¾Ğ²: 
                * 'info' - Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
                * 'debug' - Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ²ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ‚Ñ€ĞµĞ½ĞµÑ€Ğ°.
                * 'warning' - Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ
                * 'error' - Ğ²Ñ‹Ğ²Ğ¾Ğ´ÑÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
            loss_fn: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ
            optimizer: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€
            scheduler: ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸Ğº learning rate
            device: Ğ£ÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğ¹ GPU\\CPU

            log_mlflow: Ğ¤Ğ»Ğ°Ğ³ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² MLflow
            mlflow_uri: URI MLflow tracking server (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¸Ğ»Ğ¸ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹, !! HTTP !!)
            log_artifacts: Ğ¤Ğ»Ğ°Ğ³ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
            experiment_name: Ğ˜Ğ¼Ñ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° Ğ² MLflow(ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ: "Experiment_name")
            run_name: Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ² MLflow(ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ¼Ñ Ğ·Ğ°Ğ´Ğ°Ñ‘Ñ‚ÑÑ Ğ²Ğ¸Ğ´Ğ° 
                "{Ğ¸Ğ¼Ñ_Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸}_{ĞºĞ¾Ğ»_ÑĞ¿Ğ¾Ñ…}_{ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ_ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ}_{Ğ’Ñ€ĞµĞ¼Ñ}". ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: "VGG_11_ep20_lr0.001_time(11:12_19:53:16)")
            mlflow_tags: Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµĞ³Ğ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
        """

        # logger load
        self.logger = self._setup_logger(logger_lvl)
        self.logger.debug("âšª Start init")

        # model and setting learning
        self.model = model
        self.loss_fn = loss_fn 
        self.optimizer = optimizer 
        self.scheduler = scheduler
        self.device = device

        # data
        self.classes = classes
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader

        # mlflow
        self.log_mlflow = log_mlflow
        self.mlflow_uri = mlflow_uri
        self.log_artifacts = log_artifacts
        self.experiment_name = experiment_name
        self.run_name = run_name
        self.mlflow_tags = mlflow_tags

        self._validate_input()
        self.train_loader_size, self.val_loader_size, self.test_loader_size = self._get_size_datasets()

        # device
        self._setup_device(device)
        self.model.to(self.device)

        self.train_metrics = self.create_classification_metrics(
            preset = 'minimal',
            prefix = 'train_',
        )

        self.val_metrics = self.create_classification_metrics(
            preset = 'full',
            prefix = 'val_',
        )

        # metrics
        self.history = {
            'train_loss': [], 
            'train_accuracy': [],
            'val_loss': [], 
            'val_accuracy': [],
            'learning_rate': []
        }

        self.logger.debug("ğŸ Finish init")

    def _setup_logger(
            self, 
            logger_lvl: str
        ):
        """
        ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³ĞµÑ€Ğ°
        
        Args:
            logger_lvl: ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ('debug', 'info', 'warning', 'error')
        """
        logger = logging.getLogger(f"Trainer")
        
        logger.handlers.clear()

        if logger_lvl == 'debug':
            logger.setLevel(logging.DEBUG)
        elif logger_lvl == 'info':
            logger.setLevel(logging.INFO)
        elif logger_lvl == 'warning':
            logger.setLevel(logging.WARNING)
        elif logger_lvl == 'error':
            logger.setLevel(logging.ERROR)
        else:
            logger.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            "%(asctime)s | %(levelname)s | %(message)s",
            datefmt="%H:%M:%S"
        )
        
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logger.level)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
        logger.propagate = False # This fix bug for dublicatid logger
        
        logging.addLevelName(logging.INFO,    "ğŸ’™ [ INFO  ]")
        logging.addLevelName(logging.WARNING, "ğŸ’› [WARNING]")
        logging.addLevelName(logging.ERROR,   "ğŸ’” [ ERROR ]")
        logging.addLevelName(logging.DEBUG,   "ğŸ” [ DEBUG ]")

        logger.debug(f"Logger build.")
        return logger

    def _get_size_datasets(self):
        self.logger.debug("â”œğŸ”˜ Calculate size data")
    
        batch, _ = next(iter(self.train_loader))
        img_shape = batch[0].size()
        self.logger.info(f" â– Image count color:   {img_shape[0]}")
        self.logger.info(f" â– Image size:          {img_shape[1:]} (HÃ—W)")

        batch_size = len(batch)
        train_size = len(self.train_loader.dataset)
        val_size = len(self.val_loader.dataset)

        self.logger.info(f" â– Batch size:          {batch_size}")
        self.logger.info(f" â– Train data sample:   {train_size}")
        self.logger.info(f" â– Validate data sample:{val_size}")
        if self.test_loader is not None:
            test_size = len(self.test_loader.dataset)
            self.logger.info(f" â– Test data sample:   {test_size}")
        else:
            test_size = None
            self.logger.info(" â– Test data sample:    Not used")
            self.logger.warning(" Model don`t testing for test data! (test_loader is None value)")
        self.logger.debug("|â””ğŸ Finish calculate info for data")
        return train_size, val_size, test_size 

    def _validate_input(self):
        """
        Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        """
        self.logger.debug("â”œğŸ”˜ Start input value validation")

        cheks = [
            (self.model, nn.Module, "model"),
            (self.train_loader, DataLoader, "train_loader"),
            (self.val_loader, DataLoader, "val_loader"),
        ]

        for obj, type, name in cheks:
            if not isinstance(obj, type):
                self.logger.error(f"|â””ğŸ”´ {name} is not {type}. Type value is {type(obj)}")
                raise TypeError(f"{name} must be {type}")
            
            if type == DataLoader:
                try:
                    next(iter(obj.dataset))
                except StopIteration:
                    self.logger.error(f"|â””ğŸ”´ {name}({type}) is empty.")
                    raise StopIteration(f"{name}({type}) is empty.")
            
            self.logger.debug(f"|â”œğŸŸ¢ {name}: OK")

        check_and_adjust = [
            (self.test_loader, DataLoader, "test_loader", None),
            (self.loss_fn, nn.Module, "loss_fn", nn.CrossEntropyLoss()),
            (self.device, torch.device, "device", None),
        ]

        for obj, type, name, new_val in check_and_adjust :
            if not isinstance(obj, type):
                self.logger.warning(f"ğŸŸ  {name} is not {type}.")
                setattr(self, name, new_val)
                self.logger.debug(f"|â”œğŸŸ¢ {name} change in default value. ({new_val})")
            else:
                self.logger.debug(f"|â”œğŸŸ¢ {name}: OK")

        # optimizer
        if not isinstance(self.optimizer, Optimizer):
            self.logger.warning(f"ğŸŸ  optimizer is not {Optimizer}. Change in default value({optim.Adam})")
            self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
            self.logger.debug(f"|â”œğŸŸ¢ optimizer change in default value. (learning_rate = 0.001, {optim.Adam})")
        else:
            self.logger.debug(f"|â”œğŸŸ¢ optimizer: OK")

        # lr_scheduler
        if not isinstance(self.scheduler, lr_scheduler._LRScheduler):
            self.logger.warning(f"ğŸŸ  scheduler is not {lr_scheduler._LRScheduler}. Change in default value({lr_scheduler.CosineAnnealingLR})")
            self.scheduler = lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=50)
            self.logger.debug(f"|â”œğŸŸ¢ scheduler change in default value. ({lr_scheduler.CosineAnnealingLR})")
        else:
            self.logger.debug(f"|â”œğŸŸ¢ scheduler: OK")

        # mlflow test connect
        self._mlflow_test_connect()

        self.logger.debug("|â””ğŸ finish validating params")

    def _setup_device(self, device: Optional[torch.device] = None):
        """
        ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ "Ğ°Ğ¿Ğ¿Ğ°Ñ€Ğ°Ñ‚Ğ°" Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        """
        self.logger.debug("â”œğŸ”˜ Start setting device")

        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        if self.device.type == 'cuda':
            if not torch.cuda.is_available():
                self.logger.warning("ğŸŸ  error load 'CUDA'. Using 'CPU'")
                self.device = torch.device('cpu')
            else:
                # clear cache in cuda
                torch.cuda.empty_cache()
                gpu_info = torch.cuda.get_device_name(self.device)
                self.logger.debug(f"||ğŸŸ¡ GPU: {gpu_info}")

        self.logger.info(f"Training on: {self.device}")
        self.logger.debug(f"|â””ğŸŸ¢Training on: {self.device}")

    def _mlflow_test_connect(self):
        """
        Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº ÑĞµÑ€Ğ²ĞµÑ€Ñƒ mlflow
        """
        if not self.log_mlflow:
            self.logger.debug("|ğŸŸ¢ MLflow tracking: OFF")
            return
        
        try:
            self.logger.debug("|â”œğŸ”˜ Test connection for MLflow. ")
            mlflow.set_tracking_uri(self.mlflow_uri)

            _ = mlflow.search_experiments()
            self.logger.debug(f"||â”œğŸŸ¢ Connected to MLflow at {self.mlflow_uri}")
        except Exception as e:
            self.logger.error(f"||â””ğŸ”´MLflow server at {self.mlflow_uri} not available. Using local tracking.")
            mlflow.set_tracking_uri(None)

    @contextmanager
    def mlflow_run_manager(self):
        """
        ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ MLflow runs.
        """
        if not self.log_mlflow:
            yield
            return
        
        run = None
        try:
            run = mlflow.start_run(run_name=self.run_name) 
            self.mlflow_run = run
            self.logger.debug(f"|ğŸŸ¢ MLflow run started: {run.info.run_id}")
            
            yield
                        
            mlflow.end_run(status="FINISHED")
            self.logger.debug("â””ğŸ MLflow run finished successfully")
                
        except Exception as e:
            if run:
                mlflow.end_run(status="FAILED")
            
            self.logger.error(f"ğŸ”´ MLflow run failed: {e}")
            raise

        finally:
            self._ensure_run_closed(run)

    def _ensure_run_closed(self, run):
        """Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ run"""
        try:
            self.logger.debug("ğŸ”˜ Start close run in mlflow")
            active_run = mlflow.active_run()
            if active_run:
                if run and active_run.info.run_id == run.info.run_id:
                    mlflow.end_run(status="KILLED")
                elif not run:
                    mlflow.end_run(status="KILLED")
                self.logger.warning("ğŸŸ  Force-closed MLflow run")
            self.logger.debug("â””ğŸ Finish close run in mlflow")
        except:
            pass

    def _setup_mlflow(
            self,
            epoch: int,
            lr: int
        ):
        """
        ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° MLflow
        """
        if not self.log_mlflow:
            self.logger.debug("ğŸŸ¢ Tracking in MLflow: OFF")
            return

        try:
            self.logger.debug("|ğŸ”˜ START MLflow setting")
            
            mlflow.set_experiment(self.experiment_name)

            if self.run_name is None:
                time_str = time.strftime('%m:%d_%H:%M:%S')
                self.run_name = f"{self.model.__class__.__name__}_ep{epoch}_lr{lr}_time({time_str})"

            self.logger.debug(f"|â”œğŸŸ¢ run name {self.run_name}")
            self.logger.debug("|â””ğŸ FINISH MLflow setting")
        except Exception as e:
            self.logger.error(f"ğŸ”´ MLflow setup failed: {e}")
            self.logger.warning("ğŸŸ  No use tracking MLflow")
            self.log_mlflow = False

    def _mlflow_log_parameters(
            self,
            epochs: int,
        ):
        """
        Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        """
        try: 
            model_params = {
                'model_type': self.model.__class__.__name__,
                'device': self.device.type,
                'model_total_parameters': sum([p.numel() for p in self.model.parameters()]),
                'model_trainable_parameters': sum([p.numel() for p in self.model.parameters() if p.requires_grad]),
            }

            # Optim
            optimizer_params = {
                'optimizer': self.optimizer.__class__.__name__,
                'learning_rate': self.optimizer.param_groups[0]['lr']
            }
            for key, value in self.optimizer.param_groups[0].items():
                if key != 'params':
                    optimizer_params[f'optimizer_{key}'] = value
            
            data_params = {
                'data_train_sample': self.train_loader_size,
                'data_val_sample': self.val_loader_size,
                'data_test_sample': self.test_loader_size if self.test_loader_size else "Unknown",
                'batch_size': self.train_loader.batch_size,
                'classes_count': len(self.classes),
            }

            training_params = {
                'epochs': epochs,
            }

            if hasattr(self, 'scheduler') and self.scheduler:
                scheduler_params = {
                    'scheduler': self.scheduler.__class__.__name__,
                }
                if hasattr(self.scheduler, 'step_size'):
                    scheduler_params['scheduler_step_size'] = self.scheduler.step_size
                if hasattr(self.scheduler, 'gamma'):
                    scheduler_params['scheduler_gamma'] = self.scheduler.gamma
                if hasattr(self.scheduler, 'T_0'):  # CosineAnnealingWarmRestarts
                    scheduler_params['scheduler_T_0'] = self.scheduler.T_0

            if hasattr(self, 'loss_fn'):
                loss_fn_params = {
                    'loss_fn': self.loss_fn.__class__.__name__,
                }
                for attr in ['weight', 'size_average', 'reduce', 'reduction', 'ignore_index']:
                    if hasattr(self.loss_fn, attr):
                        value = getattr(self.loss_fn, attr)
                        if torch.is_tensor(value):
                            value = value.to_list()
                        loss_fn_params[f'loss_fn_{attr}'] = str(value)
                training_params.update(loss_fn_params)
            
            all_params = {
                **model_params, 
                **data_params,
                **optimizer_params,
                **training_params
            }
            mlflow.log_params(all_params)
            self.logger.debug('|ğŸŸ¢Parameters model add in MLFlow')
        except Exception as e:
            self.logger.error("Error set all params in mlflow:", e)
            raise

    def create_classification_metrics(
            self,
            preset: str = 'full',
            prefix: str = '',
        ) -> MetricCollection:
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
        
        Args:
            preset: 'minimal', 'standard', 'full'
            prefix: Ğ¿Ñ€ĞµÑ„Ğ¸ĞºÑ Ğ´Ğ»Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        Returns:
            MetricCollection Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸
        """

        num_classes = len(self.classes)
        
        # ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ğ» ÑĞ¸Ğ½Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ?
        # ĞŸĞ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾ Ğ² Ğ¼Ğ¾Ñ‘Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğµ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾
        sync_on_compute = False

        PRESETS= {
            'minimal': {
                'accuracy': Accuracy(
                    task='multiclass', 
                    num_classes=num_classes,
                    sync_on_compute=sync_on_compute
                ),
            },
            'standard': {
                'accuracy': Accuracy(
                    task='multiclass', 
                    num_classes=num_classes,
                    sync_on_compute=sync_on_compute
                ),
                'precision': Precision(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
                'recall': Recall(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
                'f1': F1Score(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
            },
            'full': {
                'accuracy': Accuracy(
                    task='multiclass', 
                    num_classes=num_classes,
                    sync_on_compute=sync_on_compute
                ),
                'precision_macro': Precision(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
                'precision_micro': Precision(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='micro',
                    sync_on_compute=sync_on_compute
                ),
                'recall_macro': Recall(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
                'recall_micro': Recall(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='micro',
                    sync_on_compute=sync_on_compute
                ),
                'f1_macro': F1Score(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='macro',
                    sync_on_compute=sync_on_compute
                ),
                'f1_micro': F1Score(
                    task='multiclass', 
                    num_classes=num_classes,
                    average='micro',
                    sync_on_compute=sync_on_compute
                ),
            },
        }
        
        if preset not in PRESETS:
            preset_available = list(PRESETS.keys())
            raise ValueError(f"Unknown preset '{preset}'. Available: {preset_available}")
        
        metrics_dict = PRESETS[preset]
        
        metrics_dict['loss'] = MeanMetric(
            sync_on_compute=sync_on_compute,
            nan_strategy='ignore'
        )
        
        collection = MetricCollection(
            metrics_dict,
            prefix=prefix,
        ).to(self.device)
        
        return collection

    def _log_epoch_metric(
            self, 
            epoch: int,
            train_metrics_value,
            val_metrics_value
        ):
        """
        Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº ÑĞ¿Ğ¾Ñ…Ğ¸ Ğ² MLflow
        """
        if not self.log_mlflow:
            return
        try:
            metrics = {
                **train_metrics_value,
                **val_metrics_value
            }

            mlflow.log_metrics(metrics, step=epoch)

        except Exception as e:
            self.logger.error("ğŸ”´ Error set metric in mlflow:", e)

    def _log_checkpoint(self, epoch: int) -> str:
        """
        Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ°
        """ 
        try:
            name = f"checkpoint_epoch_{epoch}"

            mlflow.pytorch.log_model(
                self.model,
                name=name,
                step=epoch,
                signature= self._create_mlflow_signature(),
                await_registration_for=0
            )
            self.logger.debug(f"|ğŸŸ¢ Checkpoint(save_model)")
            
        except Exception as e:
            self.logger.error(f"ğŸ”´ Error logging Ñheckpoint: {e}")

    def _create_mlflow_signature(
            self,
        ):
        """
        Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ñ‚Ñ€ÑƒÑ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        """
        sample_batch = next(iter(self.train_loader))
        imgs = sample_batch[0]

        with torch.no_grad():
            self.model.eval()
            test_output = self.model(imgs)

        input_schema = Schema([
            TensorSpec(
                type=np.dtype(np.float32),
                shape=(imgs.shape),
                name="input_images" 
            )
        ])

        output_schema = Schema([
            TensorSpec(
                type=np.dtype(np.float32),
                shape=(test_output.shape),
                name="out_labels" 
            )
        ])

        return ModelSignature(
            inputs=input_schema,
            outputs=output_schema
        )

    def _log_training_artifacts(self):
        """
        Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ²
        """
        if not self.log_mlflow or not self.log_artifacts:
            return
            
        try:
            pass
        except Exception as e:
            self.logger.error(f"ğŸ”´ Error set artifacts in mlflow: {e}")

    def _train_one(self) -> None:
        """
        ĞŸÑ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ° Ğ½Ğ¸Ñ…
        """
        self.logger.debug("ğŸ”˜ Start epoch train")
        
        self.model.train()

        for data in self._tqdm_loader(self.train_loader, "Training"):
            inputs, labels = data
            
            inputs = inputs.to(self.device)
            labels = labels.to(self.device)

            self.optimizer.zero_grad()

            # front steps
            outputs = self.model(inputs)
            loss = self.loss_fn(outputs, labels)
            
            # back steps
            loss.backward()
            self.optimizer.step()            

            _, predicted = torch.max(outputs, dim=1)
            
            self.train_metrics.update(
                preds=predicted, 
                target=labels,
                value=loss.item()
            )

            # cuda opyat ushla vsya pamyat'
            del inputs, labels, outputs, loss
        
        self.scheduler.step()

        train_metrics_value = self.train_metrics.compute()
        self.logger.info(f"Loss train: {train_metrics_value['train_loss']}")
        self.train_metrics.reset()

        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

        self.logger.debug("ğŸ Finish trainning data")
        return train_metrics_value

    def _tqdm_loader(
            self,
            data_loader: DataLoader,
            desc: str = "process"
        ):
        """
        Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ´Ğ»Ñ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ñ€Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸
        """
        return tqdm(
            data_loader,
            desc=desc,
            bar_format="{l_bar}{bar:20}{r_bar}",
            colour="blue",
            leave=False
        )

    def _validate_one(
            self
        ) -> None:
        """
        1 Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼
        """
        self.logger.debug("ğŸ”˜ Start val data")
        self.model.eval()

        with torch.no_grad():
            for data in self._tqdm_loader(self.val_loader, "Validating"):
                
                inputs, labels = data
                inputs = inputs.to(self.device)
                labels = labels.to(self.device)

                outputs = self.model(inputs)
                loss = self.loss_fn(outputs, labels)

                _, predicted = torch.max(outputs.data, 1)
                self.val_metrics.update(
                    preds=predicted, 
                    target=labels,
                    value=loss.item()
                )
                
                # cude opyat ushla vsya pamyat'
                del inputs, outputs, labels, loss

        val_metrics_value = self.val_metrics.compute()
        self.logger.info(f"Validation train: {val_metrics_value['val_loss']}")
        self.val_metrics.reset()

        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        self.logger.debug("ğŸ Finish val data")
        return val_metrics_value

    def train_with_mlflow(
            self,
            epochs: int = 20,
        ) -> nn.Module:
        """
        ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ» Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        
        Args:
            epoch: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¾Ñ… Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        """
        self.logger.info("ğŸ”˜ Start train")
        if not self.log_mlflow:
            self.logger.error("ğŸ”´ MLFlow - OFF in params the class")
            self.logger.error("ğŸ”´ TRAIN STOP")
            return self.model

        self._setup_mlflow(
            epochs, 
            self.optimizer.param_groups[0]['lr']
        )
        
        with self.mlflow_run_manager():
            
            self._mlflow_log_parameters(
                epochs
            )

            # Ğ½Ğ°Ğ´Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ÑĞ²Ğ¾Ñ‘ 
            # Ğ’ Ğ¿Ğ»Ğ°Ğ½Ğ°Ñ… Ğ¿Ğ¾Ğ¼ĞµĞ½ÑÑ‚ÑŒ
            minimal_loss = float('inf')
            best_checkpoint_patch = None

            for epoch in range(epochs):
                self.logger.info("="*20)
                self.logger.info(f"ğŸ”„ Epoch[ğŸ”¹{epoch+1}/{epochs}ğŸ”¹] start")
                train_metrics_value = self._train_one()
                val_metrics_value = self._validate_one()
                
                self._log_epoch_metric(
                    epoch+1,
                    train_metrics_value,
                    val_metrics_value
                )

                if minimal_loss > val_metrics_value['val_loss']:
                    minimal_loss = val_metrics_value['val_loss']
                    best_checkpoint_patch = self._log_checkpoint(epoch + 1)

                self.logger.info(f"ğŸŸ¢ Epoch[ğŸ”¹{epoch+1}/{epochs}ğŸ”¹] completed")

            # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹
            self._log_training_artifacts()

            self.logger.info("ğŸ Finish train")