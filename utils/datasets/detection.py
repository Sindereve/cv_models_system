import os
import glob
from pathlib import Path
from typing import Tuple, Any, List, Dict, Union
from PIL import Image
import torch

import torch
from torchvision import transforms
from torch.utils.data import Dataset

class DetectionDataset(Dataset):
    """
    Ð”Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸
    """
    
    def __init__(
        self, 
        images_dir: str,
        global_path: str,
        img_size: Tuple[int, int] = (640, 640),
        transform: Any = None,
        verbose: bool = False
    ):
        """
        Ð”Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸

        Params:
            images_dir: Ð¿ÑƒÑ‚ÑŒ Ðº Ð¿Ð°Ð¿ÐºÐµ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸ 
            global_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ð¿Ð°Ð¿ÐºÐµ, Ð³Ð´Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑÑ data.yaml 
            img_size: Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (ÑˆÐ¸Ñ€Ð¸Ð½Ð°, Ð²Ñ‹ÑÐ¾Ñ‚Ð°)
            transform: Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ. Ð•ÑÐ»Ð¸ None, Ñ‚Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð·Ð¼ÐµÐ½ÑÐµÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
            verbose: Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð•ÑÐ»Ð¸ False, Ñ‚Ð¾ Ð½Ðµ Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ
        """
        self.img_width, self.img_height = img_size
        
        self.image_paths, self.label_paths = get_images_labels_path(
            images_dir, global_path, verbose
        )

        self.transform = transform
        if self.transform is None:
            self.transform = transforms.Compose([
                transforms.Resize((self.img_height, self.img_width)),
                transforms.ToTensor()
            ])
        
    def __len__(self):
        return len(self.image_paths)
    
    def _load_image(self, idx: int) -> Tuple[torch.Tensor, Tuple[int, int]]:
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð²Ð¼ÐµÑÑ‚Ðµ Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð¼
        (Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð² RGB)
        
        Args:
            idx: Ð½Ð¾Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ

        Returns:
            Tuple[torch.Tensor, Tuple[int, int]]:
                * Ñ‚ÐµÐ½Ð·Ð¾Ñ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (C, H, W)
                * Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (ÑˆÐ¸Ñ€Ð¸Ð½Ð°, Ð²Ñ‹ÑÐ¾Ñ‚Ð°)
        """
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        image_orig_size = image.size

        image = self.transform(image)
        return image, image_orig_size
    
    def _yolo_to_xyxy(
            self, 
            yolo_box: Tuple[int, float, float, float, float], 
            orig_size: Tuple[int, int]
        ) -> Tuple[int, List[int]]:
        """
        ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ yolo(Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹) Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸ Ð² xyxy(Ð² Ð¿Ð¸ÐºÑÐµÐ»ÑŒÐ½ÑƒÑŽ)

        Args:
            yolo_box: Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð±Ð¾ÐºÑÐ° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ yolo
            orig_size: Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (ÑˆÐ¸Ñ€Ð¸Ð½Ð°, Ð²Ñ‹ÑÐ¾Ñ‚Ð°)
        Returns:
            Tuple[int, List[int]]:
                * Ð½Ð¾Ð¼ÐµÑ€ ÐºÐ»Ð°ÑÑÐ°
                * ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚ Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð¾Ð±ÑŒÐµÐºÑ‚[x_min, y_min, x_max, y_max]
        """
        orig_w, orig_h = orig_size
        class_id, x_center, y_center, width, height = yolo_box
        
        x_center *= orig_w
        y_center *= orig_h
        width *= orig_w
        height *= orig_h
        
        x_min = x_center - width / 2
        y_min = y_center - height / 2
        x_max = x_center + width / 2
        y_max = y_center + height / 2
        
        # Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð´ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€
        scale_x = self.img_width / orig_w
        scale_y = self.img_height / orig_h

        x_min *= scale_x
        x_max *= scale_x
        y_min *= scale_y
        y_max *= scale_y

        return int(class_id), [x_min, y_min, x_max, y_max]
    
    def _load_labels(
            self, 
            idx: int, 
            orig_size: Tuple[int, int]
        ) -> Dict[str, Union[torch.Tensor, torch.Tensor]]:
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ðº Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ñ‹Ð¹ Ñ torchvision

        Args:
            idx: Ð½Ð¾Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
            orig_size: Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (ÑˆÐ¸Ñ€Ð¸Ð½Ð°, Ð²Ñ‹ÑÐ¾Ñ‚Ð°)

        Returns:
            Dict['boxis': torch.Tensor, 'labels': torch.Tensor]:
                * boxis: Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹ ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð¾Ð² Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ÑÑ Ð¾Ð±ÑŒÐµÐºÑ‚Ñ‹
                * labels: id ÐºÐ»Ð°ÑÑÐ¾Ð² Ð¾Ð±ÑŒÐµÐºÑ‚Ð¾Ð²
        """
        label_path = self.label_paths[idx]
        
        boxes = []
        labels = []
        
        with open(label_path, 'r') as f:
            for line in f:
                if line.strip():
                    yolo_bbox = list(map(float, line.split()))
                    
                    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ YOLO â†’ XYXY
                    class_id, xyxy_bbox = self._yolo_to_xyxy(yolo_bbox, orig_size)
                    
                    boxes.append(xyxy_bbox)
                    labels.append(class_id)
        
        if boxes:
            return {
                'boxes': torch.tensor(boxes, dtype=torch.float32),
                'labels': torch.tensor(labels, dtype=torch.int64)
            }
        else:
            return {
                'boxes': torch.zeros((0, 4), dtype=torch.float32),
                'labels': torch.zeros(0, dtype=torch.int64)
            }
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict]:
        image, origin_size_img  = self._load_image(idx)
        target = self._load_labels(idx, origin_size_img)
        return image, target
    

def get_images_labels_path(
        images_dir: str, 
        global_path: str,
        verbose: bool = False
    ) -> Tuple[List[str], List[str]]:
    """
    ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð°Ñ€Ñ‹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ-Ð¼ÐµÑ‚ÐºÐ° Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸

    Params: 
        images_dir: Ð¿ÑƒÑ‚ÑŒ Ðº Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸
        global_path: Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿ÑƒÑ‚ÐµÐ¹
        verbose: Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ 
    Returns:
        ÐšÐ¾Ñ€Ñ‚ÐµÐ¶ Ð¸Ð· 2 ÑÐ¿Ð¸ÑÐºÐ¾Ð²:
            - ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿ÑƒÑ‚ÐµÐ¹ Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ
            - ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿ÑƒÑ‚ÐµÐ¹ Ðº ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼ Ð²ÐµÑ‚ÐºÐ°Ð¼
    """
    if verbose:
        print("ðŸ”˜[get_images_labels_path] start")

    base_path = images_dir.replace('/images','').replace("..", global_path)
    base_path = Path(base_path)

    path_images = base_path / 'images'
    path_labels = base_path / 'labels'
    
    if not path_images.exists():
        raise FileNotFoundError(f"Dir for images not found: {path_images}")
    if not path_labels.exists():
        raise FileNotFoundError(f"Dir for labels not found: {path_labels}")
    
    image_exts = ['*.png', '*.jpg', '*.jpeg']
    images_paths = []
    
    for ext in image_exts:
        images_paths.extend(path_images.glob(ext))
    images_paths = sorted([str(p) for p in images_paths])

    if not images_paths:
        raise ValueError(f"Not images found in {path_images}")
    
    if verbose:
        print("ðŸŸ¤[get_images_labels_path] path has been verified")

    valid_image_paths = []
    valid_label_paths = []
    missing_labels = []

    for img_path in images_paths:
        img_path = Path(img_path)
        img_name = img_path.stem
        labels_paths = path_labels / f"{img_name}.txt"

        if os.path.exists(labels_paths):
            valid_image_paths.append(img_path)
            valid_label_paths.append(str(labels_paths))
        else:
            missing_labels.append(img_name)

    valid_image_paths, valid_label_paths = search_bad_syntaxis_in_label(valid_image_paths, 
                                                                        valid_label_paths, 
                                                                        verbose=verbose)

    if verbose:
        print(f"ðŸŸ¢[get_images_labels_path] finish")
        print(f"   âž– count images:{len(valid_image_paths)}")
        print(f"   âž– count labels:{len(valid_label_paths)}")
        if missing_labels:
            print(f"   ðŸ”´ missing labels:{len(missing_labels)}")

    return valid_image_paths, valid_label_paths

def search_bad_syntaxis_in_label(
        valid_images_paths: List[str], 
        valid_label_paths: List[str],
        verbose: bool = False
    ) -> Tuple[list, list]:

    bad_patchs_labels = []
    indxs_bad_patch_label = []

    for indx_label, valid_label_path in enumerate(valid_label_paths):
        
        line_count = 0
        is_bad_file = False

        with open(valid_label_path, 'r') as f:
            for line in f:
                line_count+=1
                if line.strip():
                    yolo_bbox = line.split()
                    if len(yolo_bbox) != 5:

                        if not is_bad_file:
                            bad_patchs_labels.append(valid_label_path)
                            indxs_bad_patch_label.append(indx_label)
                            is_bad_file = True

    for indx_bad in indxs_bad_patch_label[::-1]:
        valid_images_paths.pop(indx_bad)
        valid_label_paths.pop(indx_bad)
    
    if verbose:
        print("ðŸŸ¡[search_bad_syntaxis_in_label] Finish")
        print(f"   âž– count bad labels:{len(bad_patchs_labels)}")

    return valid_images_paths, valid_label_paths
                    
