from typing import List, Tuple
import torch
import tqdm
from torch.utils.data import DataLoader, Subset
from torchvision import transforms, datasets

class TransformDataset(torch.utils.data.Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, index):
        x, y = self.subset[index]
        if self.transform:
            x = self.transform(x)
        return x, y

    def __len__(self):
        return len(self.subset)

def load_dataloader(
        path_data_dir: str,
        img_w_size: int = 224,
        img_h_size: int = 224,
        total_img: int = 0,
        batch_size: int = 32,
        train_ratio: float = 0.75,
        val_ratio: float = 0.15,
        is_calculate_normalize_dataset: bool = False
    ) -> Tuple[DataLoader, DataLoader, DataLoader, List[str]]:
    """
    –°–æ–∑–¥–∞–Ω–∏—ë–º Dataloader

    Args:
        path_data_dir: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞–Ω–Ω—ã–º–∏
        img_w_size: —à–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        img_h_size: –≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        total_img: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ
        batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–µ–π
        train_ratio: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
        val_ratio: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
        is_calculate_normalize_dataset: –Ω—É–∂–Ω–æ –ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ

    Returns:
        Dataloader: Dataloader –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        Dataloader: Dataloader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—Ö –¥–∞–Ω–Ω—ã—Ö
        Dataloader: Dataloader –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        list[str]: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
    """
    print("‚ö™[load_dataloader_classification] start create dataloaders")

    base_transform = transforms.Compose([
        transforms.Resize((img_h_size, img_w_size)),
        transforms.ToTensor()
    ])

    # full dataset
    full_dataset = datasets.ImageFolder(
        root=path_data_dir,
        transform=base_transform
    )

    classes = list(full_dataset.class_to_idx.keys())

    if total_img == 0:
        total_img = len(full_dataset)

    # subset load
    indxs = torch.randperm(len(full_dataset))[:total_img]
    subset = Subset(full_dataset, indxs)

    loader_for_norm = DataLoader(
        dataset=subset,
        batch_size=batch_size
    )

    if is_calculate_normalize_dataset:
        mean, std = calculate_normalize_datasets(loader_for_norm)
    else:
        mean, std = None, None

    train_transform = transforms.Compose([
        transforms.RandomResizedCrop((img_h_size, img_w_size), scale=(0.7, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
    ])

    val_train_transform = transforms.Compose([
        transforms.Resize((img_h_size, img_w_size)),
    ])

    if mean is not None:
        train_transform.transforms.append(transforms.Normalize(mean, std))
        val_train_transform.transforms.append(transforms.Normalize(mean, std))


    # split subset train/val/test 
    train_size = int(train_ratio * total_img)
    val_size = int(val_ratio * total_img)
    test_size = total_img - train_size - val_size

    train_subset, val_subset, test_subset = torch.utils.data.random_split(
        subset, [train_size, val_size, test_size]
    )

    train_dataset = TransformDataset(train_subset, transform=train_transform)
    val_dataset = TransformDataset(val_subset, transform=val_train_transform)
    test_dataset = TransformDataset(val_subset, transform=val_train_transform)

    # dataloaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=True,
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    print("üü¢[load_dataloader_classification] finish create dataloaders")
    print(f" ‚ûñ Train samples: {train_size}")
    print(f" ‚ûñ Val samples:   {val_size}")
    print(f" ‚ûñ Test samples:  {test_size}")
    print(f" ‚ûñ Classes:       {classes}")

    return train_loader, val_loader, test_loader, classes


def calculate_normalize_datasets(
        dataloader: DataLoader
    ):
    """
    –í—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞

    Args:
        dataloader: –≤–µ—Å—å –∏–∑–≤–µ—Å—Ç–Ω—ã–π –Ω–∞–º –¥–∞—Ç–∞—Å–µ—Ç
    """
    print("‚ö™[calculate_normalize_datasets] start")
    channels_sum = torch.zeros(3)
    channels_sq_sum = torch.zeros(3)
    num_batches = 0

    for data, _ in tqdm(dataloader):
        channels_sum += torch.mean(data, dim=[0,2,3])
        channels_sq_sum +=  torch.mean(data**2, dim=[0,2,3])
        num_batches += 1

    if num_batches == 0:
        raise ValueError("Dataloader –ø—É—Å—Ç")
    
    mean = channels_sum / num_batches
    std = (channels_sq_sum / num_batches - mean**2)**0.5
    print("üü¢[calculate_normalize_datasets] finish")
    return mean, std

def denormalize_image(
        tensor: torch.Tensor, 
        mean: torch.Tensor, 
        std: torch.Tensor,
    ) -> torch.Tensor:
    """
    –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

    Args:
        tensor: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ —Ç–µ–Ω–∑–æ—Ä–∞
        mean –∏ std: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏

    Return:
        –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ —Ç–µ–Ω–∑–æ—Ä–∞
    """
    denorm = transforms.Normalize(
        mean=[-m/s for m, s in zip(mean, std)],
        std=[1/s for s in std]
    )
    return denorm(tensor)