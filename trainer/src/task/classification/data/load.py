from typing import List, Tuple
import torch
import tqdm
from torch.utils.data import DataLoader, Subset
from torchvision import transforms, datasets

def load_dataloader_classification(
        path_data_dir: str,
        img_w_size: int = 224,
        img_h_size: int = 224,
        total_img: int = 0,
        batch_size: int = 32,
        train_ration: float = 0.8,
        is_calculate_normalize_dataset: bool = True
    ) -> Tuple[DataLoader, DataLoader, List[str]]:
    """
    –°–æ–∑–¥–∞–Ω–∏—ë–º Dataloader

    Args:
        path_data_dir: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞–Ω–Ω—ã–º–∏
        img_w_size: —à–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        img_h_size: –≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
        total_img: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ
        batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–µ–π
        train_ration: –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
        is_calculate_normalize_dataset: –Ω—É–∂–Ω–æ –ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ

    Returns:
        Dataloader: Dataloader –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        Dataloader: Dataloader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—Ö –¥–∞–Ω–Ω—ã—Ö
        list[str]: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
    """
    print("‚ö™[load_dataloader_classification] start create dataloaders")

    base_transform = transforms.Compose([
        transforms.Resize((img_h_size, img_w_size)),
        transforms.ToTensor()
    ])

    temp_dataset = datasets.ImageFolder(
        root=path_data_dir,
        transform=base_transform
    )

    temp_loader = DataLoader(
        temp_dataset,
        batch_size=batch_size,
        shuffle=False,
    )

    classes = temp_loader.dataset.class_to_idx

    if is_calculate_normalize_dataset:
        print("üü£[normalize_dataset] processing")
        mean, std = calculate_normalize_datasets(temp_loader)
    
        train_transform = transforms.Compose([
            transforms.RandomResizedCrop(
                size=(img_h_size, img_w_size),
                scale=(0.7, 1.0)
            ),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])

        val_transform = transforms.Compose([
            transforms.Resize(size=(img_h_size, img_w_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])
    else:
        train_transform = transforms.Compose([
            transforms.RandomResizedCrop(
                size=(img_h_size, img_w_size),
                scale=(0.7, 1.0)
            ),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
        ])

        val_transform = transforms.Compose([
            transforms.Resize(size=(img_h_size, img_w_size)),
            transforms.ToTensor(),
        ])

    if total_img == 0:
        total_img = len(temp_dataset)

    indxs = torch.randperm(len(temp_dataset))[:total_img]
    temp_dataset = Subset(temp_dataset, indxs)

    train_size = int(train_ration * total_img)
    val_size = total_img - train_size

    train_dataset, val_dataset = torch.utils.data.random_split(
        temp_dataset, [train_size, val_size]
    )

    train_dataset.dataset.transform = train_transform
    val_dataset.dataset.transform = val_transform

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
    )

    print("üü¢[load_dataloader_classification] finish create dataloaders")
    print(f" ‚ûñ Train samples: {len(train_dataset)}")
    print(f" ‚ûñ Val samples:   {len(val_dataset)}")
    print(f" ‚ûñ Classes:       {classes}")

    return train_loader, val_loader, classes


def calculate_normalize_datasets(
        dataloader: DataLoader
    ):
    """
    –í—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞

    Args:
        dataloader: –≤–µ—Å—å –∏–∑–≤–µ—Å—Ç–Ω—ã–π –Ω–∞–º –¥–∞—Ç–∞—Å–µ—Ç
    """
    print("‚ö™[calculate_normalize_datasets] start")
    channels_sum = torch.zeros(3)
    channels_sq_sum = torch.zeros(3)
    num_batches = 0

    for data, _ in tqdm(dataloader):
        channels_sum += torch.mean(data, dim=[0,2,3])
        channels_sq_sum +=  torch.mean(data**2, dim=[0,2,3])
        num_batches += 1

    if num_batches == 0:
        raise ValueError("Dataloader –ø—É—Å—Ç")
    
    mean = channels_sum / num_batches
    std = (channels_sq_sum / num_batches - mean**2)**0.5
    print("üü¢[calculate_normalize_datasets] finish")
    return mean, std

def denormalize_image(
        tensor: torch.Tensor, 
        mean: torch.Tensor, 
        std: torch.Tensor,
    ) -> torch.Tensor:
    """
    –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

    Args:
        tensor: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ —Ç–µ–Ω–∑–æ—Ä–∞
        mean –∏ std: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏

    Return:
        –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ —Ç–µ–Ω–∑–æ—Ä–∞
    """
    denorm = transforms.Normalize(
        mean=[-m/s for m, s in zip(mean, std)],
        std=[1/s for s in std]
    )
    return denorm(tensor)