{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9f49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils.datasets import load_dataloader_classification\n",
    "from utils.seed import set_global_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca735af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Finish setting random:\n",
      " âž– Random seed: 42\n",
      " âž– Use deterministic alg: True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "set_global_seed(\n",
    "    random_state=42,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185a0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âšª[load_dataloader_classification] start create dataloaders\n",
      "ðŸŸ¢[load_dataloader_classification] finish create dataloaders\n",
      " âž– Train samples: 80\n",
      " âž– Val samples:   20\n",
      " âž– Classes:       {'jerry': 0, 'tom': 1, 'tom_jerry_0': 2, 'tom_jerry_1': 3}\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, classes = load_dataloader_classification(\n",
    "    'data\\\\tom_and_jerry',\n",
    "    img_h_size=640,\n",
    "    batch_size=8,\n",
    "    img_w_size=640,\n",
    "    total_img= 100,\n",
    "    is_calculate_normalize_dataset=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e84348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.classification.resnet import ResNet\n",
    "\n",
    "model = ResNet(\n",
    "    num_class = len(classes),\n",
    "    model_name = 'resnet18',\n",
    "    weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a622cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:21 | ðŸ”Ž [ DEBUG ] | Logger build.\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | âšª Start init\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | â”œðŸ”˜ Start input value validation\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ model: OK\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ train_loader: OK\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ val_loader: OK\n",
      "15:49:21 | ðŸ’› [WARNING] | ðŸŸ  test_loader is not <class 'torch.utils.data.dataloader.DataLoader'>.\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ test_loader change in default value. (None)\n",
      "15:49:21 | ðŸ’› [WARNING] | ðŸŸ  loss_fn is not <class 'torch.nn.modules.module.Module'>.\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ loss_fn change in default value. (CrossEntropyLoss())\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ device: OK\n",
      "15:49:21 | ðŸ’› [WARNING] | ðŸŸ  optimizer is not <class 'torch.optim.optimizer.Optimizer'>. Change in default value(<class 'torch.optim.adam.Adam'>)\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ optimizer change in default value. (learning_rate = 0.001, <class 'torch.optim.adam.Adam'>)\n",
      "15:49:21 | ðŸ’› [WARNING] | ðŸŸ  scheduler is not <class 'torch.optim.lr_scheduler._LRScheduler'>. Change in default value(<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>)\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ scheduler change in default value. (<class 'torch.optim.lr_scheduler.CosineAnnealingLR'>)\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â”œðŸ”˜ Test connection for MLflow. \n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | ||â”œðŸŸ¢ Connected to MLflow at http://127.0.0.1:5000\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â””ðŸ finish validating params\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | â”œðŸ”˜ Calculate size data\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Image count color:   3\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Image size:          torch.Size([640, 640]) (HÃ—W)\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Batch size:          8\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Train data sample:   80\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Validate data sample:20\n",
      "15:49:21 | ðŸ’™ [ INFO  ] |  âž– Test data sample:    Not used\n",
      "15:49:21 | ðŸ’› [WARNING] |  Model don`t testing for test data! (test_loader is None value)\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â””ðŸ Finish calculate info for data\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | â”œðŸ”˜ Start setting device\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | ||ðŸŸ¡ GPU: NVIDIA GeForce GTX 1650\n",
      "15:49:21 | ðŸ’™ [ INFO  ] | Training on: cuda\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | |â””ðŸŸ¢Training on: cuda\n",
      "15:49:21 | ðŸ”Ž [ DEBUG ] | ðŸ Finish init\n"
     ]
    }
   ],
   "source": [
    "import models.classification.train_model as tm\n",
    "from importlib import reload\n",
    "reload(tm)\n",
    "\n",
    "my_trainer = tm.Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    classes=classes,\n",
    "    device=device,\n",
    "    # loss_fn=torch.nn.CrossEntropyLoss()\n",
    "    logger_lvl='debug'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f300b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:23 | ðŸ’™ [ INFO  ] | ðŸ”˜ Start train\n",
      "15:49:23 | ðŸ”Ž [ DEBUG ] | |ðŸ”˜ START MLflow setting\n",
      "15:49:23 | ðŸ”Ž [ DEBUG ] | |â”œðŸŸ¢ run name ResNet_ep10_lr0.001_time(12:07_15:49:23)\n",
      "15:49:23 | ðŸ”Ž [ DEBUG ] | |â””ðŸ FINISH MLflow setting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 15:49:23 ðŸ’™ [ INFO  ] mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:23 | ðŸ”Ž [ DEBUG ] | |ðŸŸ¢ MLflow run started: 10f426c5664a46959a61124bf83b4cef\n",
      "15:49:23 | ðŸ”Ž [ DEBUG ] | |ðŸŸ¢Parameters model add in MLFlow\n",
      "15:49:23 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:23 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹1/10ðŸ”¹] start\n",
      "15:49:23 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:26 | ðŸ’™ [ INFO  ] | Loss train: 0.5254608988761902\n",
      "15:49:27 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:27 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:27 | ðŸ’™ [ INFO  ] | Validation train: 1.023355484008789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:27 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:49:27 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹1/10ðŸ”¹] completed\n",
      "15:49:27 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:27 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹2/10ðŸ”¹] start\n",
      "15:49:27 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:31 | ðŸ’™ [ INFO  ] | Loss train: 0.47724246978759766\n",
      "15:49:31 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:31 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:31 | ðŸ’™ [ INFO  ] | Validation train: 1.2063931226730347\n",
      "15:49:31 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:32 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹2/10ðŸ”¹] completed\n",
      "15:49:32 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:32 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹3/10ðŸ”¹] start\n",
      "15:49:32 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:35 | ðŸ’™ [ INFO  ] | Loss train: 0.4994012713432312\n",
      "15:49:35 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:35 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:36 | ðŸ’™ [ INFO  ] | Validation train: 1.074872612953186\n",
      "15:49:36 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:36 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹3/10ðŸ”¹] completed\n",
      "15:49:36 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:36 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹4/10ðŸ”¹] start\n",
      "15:49:36 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:39 | ðŸ’™ [ INFO  ] | Loss train: 0.4997311532497406\n",
      "15:49:39 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:39 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:40 | ðŸ’™ [ INFO  ] | Validation train: 1.1066502332687378\n",
      "15:49:40 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:49:40 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹4/10ðŸ”¹] completed\n",
      "15:49:40 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:40 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹5/10ðŸ”¹] start\n",
      "15:49:40 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:44 | ðŸ’™ [ INFO  ] | Loss train: 0.5020306706428528\n",
      "15:49:44 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:44 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:45 | ðŸ’™ [ INFO  ] | Validation train: 1.1163982152938843\n",
      "15:49:45 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:45 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹5/10ðŸ”¹] completed\n",
      "15:49:45 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:45 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹6/10ðŸ”¹] start\n",
      "15:49:45 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:48 | ðŸ’™ [ INFO  ] | Loss train: 0.4893167018890381\n",
      "15:49:48 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:48 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:49 | ðŸ’™ [ INFO  ] | Validation train: 1.0196707248687744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:49 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:49:49 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹6/10ðŸ”¹] completed\n",
      "15:49:49 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:49 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹7/10ðŸ”¹] start\n",
      "15:49:49 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:53 | ðŸ’™ [ INFO  ] | Loss train: 0.41782957315444946\n",
      "15:49:53 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:53 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:54 | ðŸ’™ [ INFO  ] | Validation train: 1.1709758043289185\n",
      "15:49:54 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:54 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹7/10ðŸ”¹] completed\n",
      "15:49:54 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:54 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹8/10ðŸ”¹] start\n",
      "15:49:54 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:57 | ðŸ’™ [ INFO  ] | Loss train: 0.412121444940567\n",
      "15:49:57 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:49:57 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.70it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:49:58 | ðŸ’™ [ INFO  ] | Validation train: 1.0815874338150024\n",
      "15:49:58 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:49:58 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹8/10ðŸ”¹] completed\n",
      "15:49:58 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:49:58 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹9/10ðŸ”¹] start\n",
      "15:49:58 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:02 | ðŸ’™ [ INFO  ] | Loss train: 0.5371451377868652\n",
      "15:50:02 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:50:02 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:03 | ðŸ’™ [ INFO  ] | Validation train: 1.0334653854370117\n",
      "15:50:03 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:50:03 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹9/10ðŸ”¹] completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:03 | ðŸ’™ [ INFO  ] | ====================\n",
      "15:50:03 | ðŸ’™ [ INFO  ] | ðŸ”„ Epoch[ðŸ”¹10/10ðŸ”¹] start\n",
      "15:50:03 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start epoch train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:06 | ðŸ’™ [ INFO  ] | Loss train: 0.4802633225917816\n",
      "15:50:06 | ðŸ”Ž [ DEBUG ] | ðŸ Finish trainning data\n",
      "15:50:06 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:07 | ðŸ’™ [ INFO  ] | Validation train: 1.146636962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:07 | ðŸ”Ž [ DEBUG ] | ðŸ Finish val data\n",
      "15:50:08 | ðŸ’™ [ INFO  ] | ðŸŸ¢ Epoch[ðŸ”¹10/10ðŸ”¹] completed\n",
      "15:50:08 | ðŸ’™ [ INFO  ] | ðŸ Finish train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 15:50:08 ðŸ’™ [ INFO  ] mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/07 15:50:08 ðŸ’™ [ INFO  ] mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run ResNet_ep10_lr0.001_time(12:07_15:49:23) at: http://127.0.0.1:5000/#/experiments/446987320794286209/runs/10f426c5664a46959a61124bf83b4cef\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/446987320794286209\n",
      "15:50:08 | ðŸ”Ž [ DEBUG ] | â””ðŸ MLflow run finished successfully\n",
      "15:50:08 | ðŸ”Ž [ DEBUG ] | ðŸ”˜ Start close run in mlflow\n",
      "15:50:08 | ðŸ”Ž [ DEBUG ] | â””ðŸ Finish close run in mlflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:08 | ðŸ”Ž [ DEBUG ] | |ðŸ”˜ Start async checkpoint save\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:50:08 | ðŸ’” [ ERROR ] | ðŸ”´ Async checkpoint error: 'Trainer' object has no attribute '_log_checkpoint_sync'\n",
      "15:50:08 | ðŸ”Ž [ DEBUG ] | |ðŸ”˜ Start async checkpoint save\n",
      "15:50:08 | ðŸ’” [ ERROR ] | ðŸ”´ Async checkpoint error: 'Trainer' object has no attribute '_log_checkpoint_sync'\n"
     ]
    }
   ],
   "source": [
    "my_trainer.train_with_mlflow(\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f13605",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sinde\\miniconda3\\envs\\cv_exp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1929\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1930\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1931\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1932\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1933\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'ResNet' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb47759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
